{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "506/506 [==============================] - 24s 44ms/step - loss: 0.1944 - accuracy: 0.9186 - val_loss: 0.1188 - val_accuracy: 0.9535\n",
      "Epoch 2/5\n",
      "506/506 [==============================] - 23s 46ms/step - loss: 0.0910 - accuracy: 0.9645 - val_loss: 0.1071 - val_accuracy: 0.9580\n",
      "Epoch 3/5\n",
      "506/506 [==============================] - 24s 47ms/step - loss: 0.0597 - accuracy: 0.9777 - val_loss: 0.1204 - val_accuracy: 0.9560\n",
      "Epoch 4/5\n",
      "506/506 [==============================] - 24s 47ms/step - loss: 0.0396 - accuracy: 0.9859 - val_loss: 0.1500 - val_accuracy: 0.9541\n",
      "Epoch 5/5\n",
      "506/506 [==============================] - 23s 46ms/step - loss: 0.0295 - accuracy: 0.9886 - val_loss: 0.1575 - val_accuracy: 0.9524\n",
      "281/281 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9535634743875279,\n",
       " 0.9595959595959596,\n",
       " 0.9434180138568129,\n",
       " 0.9514382205659717,\n",
       " 0.9532143832724925)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Load the datasets\n",
    "true_news = pd.read_csv('true_news.csv')\n",
    "fake_news = pd.read_csv('fake_news.csv')\n",
    "\n",
    "# Add a label column to distinguish between true and fake news\n",
    "true_news['label'] = 'True'\n",
    "fake_news['label'] = 'Fake'\n",
    "\n",
    "# Combine the datasets\n",
    "news_data = pd.concat([true_news, fake_news])\n",
    "\n",
    "# Clean the titles\n",
    "news_data['cleaned_title'] = news_data['title'].apply(clean_text)\n",
    "\n",
    "# Tokenize the titles\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(news_data['cleaned_title'])\n",
    "X_title = tokenizer.texts_to_sequences(news_data['cleaned_title'])\n",
    "\n",
    "# Pad the sequences\n",
    "X_title = pad_sequences(X_title, maxlen=50)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(news_data['label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_title, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "input_layer = Input(shape=(X_title.shape[1],))\n",
    "embedding_layer = Embedding(input_dim=5000, output_dim=128, input_length=X_title.shape[1])(input_layer)\n",
    "spatial_dropout_layer = SpatialDropout1D(0.2)(embedding_layer)\n",
    "lstm_layer = LSTM(100, dropout=0.2, recurrent_dropout=0.2)(spatial_dropout_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "accuracy, precision, recall, f1, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n",
      "The predicted label for the given news title is: Fake\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Save the trained model\n",
    "\n",
    "model.save('news_classification_model.h5')\n",
    "# Function for inference\n",
    "def predict_news_title(model, tokenizer, title):\n",
    "    # Clean the title\n",
    "    cleaned_title = clean_text(title)\n",
    "    # Tokenize the title\n",
    "    title_sequence = tokenizer.texts_to_sequences([cleaned_title])\n",
    "    # Pad the sequence\n",
    "    padded_title = pad_sequences(title_sequence, maxlen=50)\n",
    "    # Predict\n",
    "    prediction = model.predict(padded_title)\n",
    "    # Convert prediction to label\n",
    "    label = 'True' if prediction > 0.5 else 'Fake'\n",
    "    return label\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('news_classification_model.h5')\n",
    "\n",
    "# Example usage\n",
    "example_title = \"Breaking news: Major breakthrough in AI research\"\n",
    "predicted_label = predict_news_title(loaded_model, tokenizer, example_title)\n",
    "print(f\"The predicted label for the given news title is: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool outputs submitted successfully.\n",
      "Bot: [TextContentBlock(text=Text(annotations=[], value=\"Here are the latest news headlines from Germany:\\n\\n1. **European Elections Impact**: Far-right AfD politicians were attacked in two locations in Germany amidst the EU parliamentary elections, which also saw a varied voter age with 16-year-olds voting in Germany and Belgium.\\n\\n2. **Cybersecurity Efforts**: The Netherlands, France, and Germany led a significant operation against the largest ever seen botnet, which could have implications for future cybersecurity measures.\\n\\n3. **Climate and Technology**: Germany is gearing up to launch a European 'sovereign cloud' by 2025 with significant investment, reflecting an ongoing trend towards digital sovereignty and secure data environments.\\n\\n4. **Social Issues and Developments**:\\n   - Germany is trialing a four-day work week to test its impact on work-life balance and productivity.\\n   - Floods in southern Germany have tragically killed at least four people, highlighting ongoing concerns about climate change and infrastructure.\\n   - Germany's continued usage of fax machines in business cultures is changing as new technologies and systems are adopted for efficiency.\\n\\n5. **Cultural and Sports News**:\\n   - A German novel exploring a complex love affair won the 2024 International Booker Prize, signaling a recognition of German literature on the global stage.\\n   - Real Madrid’s German player Antonio Rüdiger addressed rumors about a training incident with a German teammate, reflecting the spotlight on German athletes internationally.\\n\\nThese headlines sketch a dynamic picture of Germany in the context of political changes, social developments, technological advances, and cultural achievements.\"), type='text')]\n",
      "Time taken: 23.98986554145813\n",
      "Tool outputs submitted successfully.\n",
      "Bot: [TextContentBlock(text=Text(annotations=[], value='The latest headline from Europe is focused on a health concern:\\n\\n- **Dengue Fever Rise**: The spread of the tiger mosquito has led to an increase in dengue fever cases across Europe, according to a report from BBC.com. This highlights growing concerns about the impact of climate change on disease patterns and the spread of vector-borne illnesses.'), type='text')]\n",
      "Time taken: 11.09408950805664\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wavio\n",
    "import webrtcvad\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from colorama import Fore, Style\n",
    "import json\n",
    "from newsapi import NewsApiClient\n",
    "import time\n",
    "import joblib\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import asyncio\n",
    "import websockets\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize OpenAI API client\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Create the assistant with both search and fake news detection tools\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a news bot. You can search for news articles based on keywords or provide the latest news headlines in a very short summary news digest. You also detect fake news using a pre-trained model.\",\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"search_news\",\n",
    "                \"description\": \"Search for news articles based on keywords\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Keywords to search for, e.g., 'technology', 'politics'\"\n",
    "                        },\n",
    "                        \"type\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Type of news to search for, either 'top headlines' or 'everything'\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\", \"type\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"detect_fake_news\",\n",
    "                \"description\": \"Detect fake news using a pre-trained model\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"text\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Text to detect fake news for, e.g., 'The article is fake'\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"text\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize NewsApiClient\n",
    "newsapi = NewsApiClient(api_key='925c20de4a3543118751067d2e96e331')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace newlines and other escape sequences with a space\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Replace extra spaces with commas\n",
    "    text = ','.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to load the best model\n",
    "def load_best_model(model_path='best_model.pkl'):\n",
    "    try:\n",
    "        # Load the model from the specified path\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"Model loaded from {model_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the fake news detection model\n",
    "model = load_best_model()\n",
    "\n",
    "def clean_title_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Function for inference\n",
    "def detect_fake_news(title, model=model, tokenizer=tokenizer):\n",
    "    # Clean the title\n",
    "    cleaned_title = clean_title_text(title)\n",
    "    # Tokenize the title\n",
    "    title_sequence = tokenizer.texts_to_sequences([cleaned_title])\n",
    "    # Pad the sequence\n",
    "    padded_title = pad_sequences(title_sequence, maxlen=50)\n",
    "    # Predict\n",
    "    prediction = model.predict(padded_title)\n",
    "    # Convert prediction to label\n",
    "    label = 'True' if prediction > 0.5 else 'Fake'\n",
    "    return label\n",
    "\n",
    "def search_news(query, type):\n",
    "    if type == \"top headlines\":\n",
    "        headlines = newsapi.get_top_headlines(q=query, language='en', country=\"us\")\n",
    "        headline_titles = []\n",
    "        if headlines['totalResults'] > 0:\n",
    "            for headline in headlines['articles']:\n",
    "                headline_titles.append(headline['title'])\n",
    "            return clean_text(' '.join(headline_titles))\n",
    "    articles = newsapi.get_everything(q=query, language='en')\n",
    "    article_titles = []\n",
    "    for article in articles['articles']:\n",
    "        article_titles.append(article['title'])\n",
    "    return clean_text(' '.join(article_titles))\n",
    "\n",
    "# Function to record audio using WebRTC VAD\n",
    "def record_audio_with_vad():\n",
    "    \"\"\"Record audio from microphone using Voice Activity Detection.\"\"\"\n",
    "    vad = webrtcvad.Vad(3)  # Aggressiveness mode can be 0 to 3. 3 is the most aggressive.\n",
    "    frames = []\n",
    "    silent_chunks_count = 0  # Counter for consecutive silent chunks\n",
    "\n",
    "    with sd.InputStream(samplerate=48000, channels=2, dtype=np.int16) as stream:\n",
    "        print(\"Start speaking...\")\n",
    "        while True:\n",
    "            audio_chunk, _ = stream.read(int(48000 * 0.01))  # 10ms chunk\n",
    "            if vad.is_speech(audio_chunk.tobytes(), 48000):\n",
    "                print(\"Recording...\")\n",
    "                frames.append(audio_chunk)\n",
    "                break\n",
    "\n",
    "        while True:\n",
    "            audio_chunk, _ = stream.read(int(48000 * 0.01))  # 10ms chunk\n",
    "            frames.append(audio_chunk)\n",
    "            if vad.is_speech(audio_chunk.tobytes(), 48000):\n",
    "                silent_chunks_count = 0  # Reset the counter if speech is detected\n",
    "            else:\n",
    "                silent_chunks_count += 1\n",
    "\n",
    "            if silent_chunks_count >= 230:  # 3 seconds of silence\n",
    "                print(\"Speech ended.\")\n",
    "                break\n",
    "\n",
    "    audio_data = np.concatenate(frames, axis=0)\n",
    "    temp_filename = \"temp_recording_with_vad.wav\"\n",
    "    wavio.write(temp_filename, audio_data, 48000)\n",
    "    return temp_filename\n",
    "\n",
    "def audio_to_text(audio_file_path, client):\n",
    "    \"\"\"Convert audio to text using Whisper ASR.\"\"\"\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        transcript = client.audio.translations.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file\n",
    "        )\n",
    "    return transcript.text\n",
    "\n",
    "# Create a single thread for the session\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 2  # in seconds\n",
    "\n",
    "async def handler(websocket, path):\n",
    "    while True:\n",
    "        message = await websocket.recv()\n",
    "        print(f\"Received message: {message}\")\n",
    "\n",
    "        if message == \"CHAT\":\n",
    "            retries = 0\n",
    "            while retries < MAX_RETRIES:\n",
    "                try:\n",
    "                    # Record audio from microphone using VAD\n",
    "                    audio_file_path = record_audio_with_vad()\n",
    "\n",
    "                    # Convert audio to text\n",
    "                    user_message = audio_to_text(audio_file_path, client)\n",
    "                    print(f\"User said: {user_message}\")\n",
    "\n",
    "                    message = client.beta.threads.messages.create(\n",
    "                        thread_id=thread.id,\n",
    "                        role=\"user\",\n",
    "                        content=user_message\n",
    "                    )\n",
    "\n",
    "                    run = client.beta.threads.runs.create(\n",
    "                        thread_id=thread.id,\n",
    "                        assistant_id=assistant.id,\n",
    "                    )\n",
    "\n",
    "                    tool_outputs = []\n",
    "                    if hasattr(run.required_action, 'submit_tool_outputs'):\n",
    "                        for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "                            query_dict = json.loads(tool.function.arguments)\n",
    "\n",
    "                            if tool.function.name == \"search_news\":\n",
    "                                query_value = query_dict['query']\n",
    "                                type_value = query_dict['type']\n",
    "                                articles = search_news(query=query_value, type=type_value)\n",
    "                                tool_outputs.append({\n",
    "                                    \"tool_call_id\": tool.id,\n",
    "                                    \"output\": json.dumps(articles)\n",
    "                                })\n",
    "\n",
    "                            if tool.function.name == \"detect_fake_news\":\n",
    "                                text_value = query_dict['text']\n",
    "                                label = detect_fake_news(text_value)\n",
    "                                tool_outputs.append({\n",
    "                                    \"tool_call_id\": tool.id,\n",
    "                                    \"output\": json.dumps({\"label\": label})\n",
    "                                })\n",
    "\n",
    "                        if tool_outputs:\n",
    "                            try:\n",
    "                                run = client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "                                    thread_id=thread.id,\n",
    "                                    run_id=run.id,\n",
    "                                    tool_outputs=tool_outputs\n",
    "                                )\n",
    "                                print(\"Tool outputs submitted successfully.\")\n",
    "                            except Exception as e:\n",
    "                                print(\"Failed to submit tool outputs:\", e)\n",
    "                        else:\n",
    "                            print(\"No tool outputs to submit.\")\n",
    "\n",
    "                    if run.status == 'completed':\n",
    "                        messages = client.beta.threads.messages.list(\n",
    "                            thread_id=thread.id\n",
    "                        )\n",
    "                        print(\"Bot:\", messages.data[0].content)\n",
    "                        await websocket.send(messages.data[0].content)\n",
    "                        break  # If successful, break out of the retry loop\n",
    "                    else:\n",
    "                        print(\"Run status:\", run.status)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    retries += 1\n",
    "                    if retries < MAX_RETRIES:\n",
    "                        print(f\"Retrying {retries}/{MAX_RETRIES} ...\")\n",
    "                        time.sleep(RETRY_DELAY)\n",
    "                    else:\n",
    "                        print(\"Max retries reached. Sending an error message.\")\n",
    "                        await websocket.send(\"Error processing request. Please try again later.\")\n",
    "        else:\n",
    "            await websocket.send(f\"Echo: {message}\")\n",
    "\n",
    "start_server = websockets.serve(\n",
    "    handler, \n",
    "    \"192.168.146.105\", \n",
    "    80,\n",
    "    ping_interval=30, \n",
    "    ping_timeout=120\n",
    ")\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(start_server)\n",
    "asyncio.get_event_loop().run_forever()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
